{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee344e0e-fd27-4767-ba94-55e61c82b3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Word Frequencies\n",
      "---------------------------\n",
      "Word             Frequency\n",
      "---------------------------\n",
      "the                  1574\n",
      "and                  1061\n",
      "of                    726\n",
      "a                     702\n",
      "to                    675\n",
      "it                    543\n",
      "in                    523\n",
      "he                    493\n",
      "was                   427\n",
      "his                   418\n",
      "i                     365\n",
      "scrooge               363\n",
      "that                  349\n",
      "with                  267\n",
      "you                   245\n",
      "s                     237\n",
      "as                    228\n",
      "said                  221\n",
      "had                   206\n",
      "him                   198\n",
      "\n",
      "\n",
      "Top 10 Bigram Frequencies\n",
      "--------------------------\n",
      "Bigram                     Frequency\n",
      "-------------------------------------\n",
      "in the                           144\n",
      "of the                           106\n",
      "it was                            98\n",
      "said scrooge                      96\n",
      "the ghost                         81\n",
      "original manuscript               71\n",
      "manuscript of                     66\n",
      "of page                           66\n",
      "illustration original             65\n",
      "and the                           61\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Rishi Raj Das\n",
    "Student Number: 165212234\n",
    "Description: This program reads a text file, processes its contents,\n",
    "counts how often each word appears using a dictionary (hash table),\n",
    "and prints the 20 most frequent words in a table format.\n",
    "It also implements a bonus feature that computes bigram frequencies\n",
    "(pairs of consecutive words) and prints the 10 most frequent bigrams.\n",
    "\"\"\"\n",
    "def read_text(filename):\n",
    "    #Reads the contents of a text file and returns it as a string.\n",
    "    try:\n",
    "        # Open the file and read all text into a single string\n",
    "        with open(filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} was not found.\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error:{e}\")\n",
    "        return \"\"\n",
    "\n",
    "def preprocess(text):\n",
    "    #Converts text to lowercase, removes punctuation, and splits it into a list of words.\n",
    "    text = text.lower() #standardizing lowercase\n",
    "    cleaned_text = \"\"\n",
    "\n",
    "    for ch in text:\n",
    "        if ch.isalpha() or ch.isspace():\n",
    "            cleaned_text += ch  #Keep letters and spaces\n",
    "        else:\n",
    "            cleaned_text += \" \" #replace punctuation with spaces\n",
    "    return cleaned_text.split()\n",
    "'''\n",
    "Other way to do it, but inefficient.\n",
    "And IDK if I am able to use 'import string' for the project or not. ¯\\_(ツ)_/¯\n",
    "    punctuations = \".,!?;:\\\"'()[]{}<>-_/\\\\|@#$%^&*~`+=\"\n",
    "    for p in punctuations:\n",
    "        text_no_punc = text.replace(p, \" \")\n",
    "    words = text_no_punc.split()\n",
    "'''\n",
    "def count_words(words):\n",
    "    #Builds a dictionary mapping each word to its frequency.\n",
    "    word_freq = {} #Dictionary used as hash table\n",
    "\n",
    "    for wd in words:\n",
    "        if wd in word_freq:\n",
    "            word_freq[wd] += 1   #Icrements the count if word has been encountered before\n",
    "        else:\n",
    "            word_freq[wd] = 1    #Catches the first occurence\n",
    "    \n",
    "    return word_freq\n",
    "\n",
    "def get_top(word_freq, n=20):\n",
    "    #Convert dictionary items to list and sorts by frequency\n",
    "    sorted_list = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_list[:n]\n",
    "\n",
    "def display_func(top_words):\n",
    "    print(\"Top 20 Word Frequencies\")\n",
    "    print(\"-\"*27)\n",
    "    #Literally spent 15 minutes looking up word alignments.(--_--)\n",
    "    print(f\"{'Word':<15} {'Frequency':>10}\")\n",
    "    print(\"-\"*27)\n",
    "\n",
    "    for word, freq in top_words:\n",
    "        print(f\"{word:<15}{freq:>10}\")\n",
    "\n",
    "#Bonus Task: Bigram Frequency\n",
    "def identify_bigram(words):\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        word_pair = (words[i], words[i + 1]) #Putting the pair in a tuple\n",
    "        bigrams.append(word_pair)\n",
    "    return bigrams\n",
    "\n",
    "def count_bigrams(bigrams):\n",
    "    #Same logic as count_words()\n",
    "    bigram_freq = {}\n",
    "\n",
    "    for bg in bigrams:\n",
    "        if bg in bigram_freq:\n",
    "            bigram_freq[bg] += 1\n",
    "        else:\n",
    "            bigram_freq[bg] = 1\n",
    "    return bigram_freq\n",
    "\n",
    "def display_func_bigram(top_bigrams):\n",
    "    print(\"\\nTop 10 Bigram Frequencies\")\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"{'Bigram':<25} {'Frequency':>10}\")\n",
    "    print(\"-\" * 37)\n",
    "\n",
    "    for (w1, w2), freq in top_bigrams:\n",
    "        bigram_str = f\"{w1} {w2}\"     #converting tuple to readable text\n",
    "        print(f\"{bigram_str:<25} {freq:>10}\")\n",
    "    \n",
    "def main():\n",
    "    filename = \"adventures_of_huckleberry_finn.txt\"\n",
    "    text = read_text(filename)\n",
    "\n",
    "    words = preprocess(text)\n",
    "    word_frequency = count_words(words)\n",
    "    top_words = get_top(word_frequency, n=20)\n",
    "    print()\n",
    "    display_func(top_words)\n",
    "\n",
    "    #Bonus Task\n",
    "    bigrams = identify_bigram(words)\n",
    "    bigram_freq = count_bigrams(bigrams)\n",
    "    top_bigrams = get_top(bigram_freq, n=10) #Reusing get_top function for the sorted list\n",
    "    print()\n",
    "    display_func_bigram(top_bigrams)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1a04f-2694-40d5-af1b-bbf535771767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311bfc5-1f76-4ae4-8b31-08acb69d4eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
